{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bcbd4c",
   "metadata": {},
   "source": [
    "**Global Cancer Patients 데이터셋**\n",
    "\n",
    "2015년부터 2024년까지 보고된 전 세계 암 환자 데이터를 포함하고 있으며, 암의 진단, 치료, 생존에 영향을 미치는 주요 요인들을 시뮬레이션한 데이터입니다.\n",
    "\n",
    "제공된 학습용 데이터(cacner_train.csv)를 이용하여 암의 심각도(Severity)를 예측하는 모델을 개발하고, 개발한 모델에 기반하여 평가용 데이터(cancer_test.csv)에 적용하여 얻은 암의 심각도 예측 값을 아래 [제출형식]에 따라 csv 파일로 생성하여 제출하시오.\n",
    "- 예측 결과는 F1 Score(macro) 평가지표에 따라 평가함\n",
    "- 성능이 우수한 예측 모델을 구축하기 위해서는 데이터 정제, Feature Engineering, 하이퍼 파라미터(hyper parameter) 최적화, 모델 비교 등이 필요할 수 있음. 다만, 과적합에 유의하여야 함\n",
    "\n",
    "\n",
    "[[제출 형식]]\n",
    "- 가. CSV 파일명: result.csv(파일명에 디렉토리/폴더 지정불가\n",
    "- 나. 예측 칼럼명 : pred\n",
    "- 다. 제출 칼럼 개수 : pred 칼럼 1개\n",
    "- 라. 평가용 데이터 개수와 예측 결과 데이터 개수 일치 : 2,193개\n",
    "\n",
    "[[제공 데이터]]\n",
    "- 데이터 목록\n",
    "- cancer_train.csv : 학습용 데이터, 5,115개\n",
    "- cancer_test.csv : 평가용 데이터, 2,193개\n",
    "- 평가용 데이터는 'Severity' 칼럼 미제공\n",
    "\n",
    "[[ CSV 파일 제출 방법 ]]\n",
    "- CSV 파일명 : result.csv\n",
    "- 암의 심각도 칼럼명 : pred\n",
    "- 제출 CSV 파일 형식 예시\n",
    "        pred\n",
    "        High\n",
    "        Low\n",
    "        High\n",
    "        Medium\n",
    "        Medium\n",
    "\n",
    "* 소수점 아래자릿수는 별도 지정하지 않음\n",
    "* pred 칼럼 데이터 수는 2,193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea872c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9905, 0.9433, F1: 0.9907, 0.9449\n",
      "pred  \n",
      "Medium    893\n",
      "High      753\n",
      "Low       547\n",
      "Name: count, dtype: int64\n",
      "pred  \n",
      "Medium    0.407205\n",
      "High      0.343365\n",
      "Low       0.249430\n",
      "Name: proportion, dtype: float64\n",
      "Severity\n",
      "Medium    0.410948\n",
      "High      0.335875\n",
      "Low       0.253177\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pd.set_option('display.max_column', 100)\n",
    "\n",
    "# 성능평가 함수\n",
    "def get_scores(model, x_train, x_test, y_train, y_test):\n",
    "    A = model.score(x_train, y_train)\n",
    "    B = model.score(x_test, y_test)\n",
    "    y_pred1 = model.predict(x_train)\n",
    "    y_pred2 = model.predict(x_test)\n",
    "    C = f1_score(y_train, y_pred1, average=\"macro\")\n",
    "    D = f1_score(y_test, y_pred2, average=\"macro\")\n",
    "    return f\"acc: {A:.4f}, {B:.4f}, F1: {C:.4f}, {D:.4f}\"\n",
    "\n",
    "path = \"https://raw.githubusercontent.com/Soyoung-Yoon/bigdata/main/\"\n",
    "train = pd.read_csv(path + \"cancer_train.csv\")\n",
    "test = pd.read_csv(path + \"cancer_test.csv\")\n",
    "# print(train.head(5)) # 5115\n",
    "# print(test.tail(5))  # 2193\n",
    "\n",
    "# 데이터 전처리\n",
    "X = train.drop(columns=['Severity'])\n",
    "X_all = pd.concat([X, test])\n",
    "columns_obj = X_all.select_dtypes(include='object').columns\n",
    "for col in columns_obj:\n",
    "    X_all[col] = LabelEncoder().fit_transform(X_all[col])\n",
    "le = LabelEncoder()\n",
    "Y = pd.Series(le.fit_transform(train['Severity']), name=\"Severity\")\n",
    "temp = StandardScaler().fit_transform(X_all)\n",
    "X_all = pd.DataFrame(temp, columns=X_all.columns)\n",
    "\n",
    "# 데이터 재분배\n",
    "X = X_all.iloc[:len(X), :]\n",
    "X_submission = X_all.iloc[len(X):, :]\n",
    "# (5115, 14) (5115,) (2193, 14)\n",
    "temp = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=1234)\n",
    "x_train, x_test, y_train, y_test = temp\n",
    "# (4092, 14) (1023, 14) (4092,) (1023,)\n",
    "\n",
    "# 모델생성\n",
    "model1 = LogisticRegression().fit(x_train, y_train)\n",
    "# print(get_scores(model1, x_train, x_test, y_train, y_test))\n",
    "# acc: 0.9856, 0.9795, F1: 0.9858, 0.9795\n",
    "\n",
    "# model2 = DecisionTreeClassifier(random_state=1234).fit(x_train, y_train)\n",
    "# print(get_scores(model2, x_train, x_test, y_train, y_test)) # acc: 1.0000, 0.8152, F1: 1.0000, 0.8214\n",
    "# print(model2.get_depth()) # 14\n",
    "# for d in range(3, 10):\n",
    "#     model2 = DecisionTreeClassifier(max_depth=d, random_state=1234).fit(x_train, y_train)\n",
    "#     print(f\"{d}: \", get_scores(model2, x_train, x_test, y_train, y_test))\n",
    "# 6:  acc: 0.8575, 0.8045, F1: 0.8615, 0.8122\n",
    "model2 = DecisionTreeClassifier(max_depth=6, random_state=1234).fit(x_train, y_train)\n",
    "# print(get_scores(model2, x_train, x_test, y_train, y_test))\n",
    "# acc: 0.8575, 0.8045, F1: 0.8615, 0.8122\n",
    "\n",
    "# model3 = RandomForestClassifier(random_state=1234).fit(x_train, y_train)\n",
    "# print(get_scores(model3, x_train, x_test, y_train, y_test)) # acc: 1.0000, 0.9267, F1: 1.0000, 0.9295\n",
    "# for d in range(3, 10):\n",
    "#     model3 = RandomForestClassifier(max_depth=d,random_state=1234).fit(x_train, y_train)\n",
    "#     print(d, get_scores(model3, x_train, x_test, y_train, y_test))\n",
    "# 4 acc: 0.8898, 0.8661, F1: 0.8942, 0.8705\n",
    "model3 = RandomForestClassifier(max_depth=4,random_state=1234).fit(x_train, y_train)\n",
    "# print(get_scores(model3, x_train, x_test, y_train, y_test))\n",
    "# acc: 0.8898, 0.8661, F1: 0.8942, 0.8705\n",
    "\n",
    "model4 = AdaBoostClassifier(random_state=1234).fit(x_train, y_train)\n",
    "# print(get_scores(model4, x_train, x_test, y_train, y_test)) # acc: 0.7923, 0.7703, F1: 0.7871, 0.7653\n",
    "\n",
    "model5 = GradientBoostingClassifier(random_state=1234).fit(x_train, y_train)\n",
    "# print(get_scores(model5, x_train, x_test, y_train, y_test)) # acc: 0.8563, 0.8172, F1: 0.8605, 0.8227\n",
    "\n",
    "# 모델선택, 제출파일 생성\n",
    "f_model = model3\n",
    "y_pred_num = f_model.predict(X_submission)\n",
    "y_pred = le.inverse_transform(y_pred_num)\n",
    "pd.DataFrame({'pred': y_pred}).to_csv(\"result_02(2기).csv\", index=False)\n",
    "\n",
    "# 제출파일 확인\n",
    "temp = pd.read_csv(\"result_02(2기).csv\")\n",
    "print(temp.value_counts())\n",
    "print(temp.value_counts(normalize=True))\n",
    "Y = pd.Series(le.inverse_transform(Y), name=\"Severity\")\n",
    "print(Y[:len(X)].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b416a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
