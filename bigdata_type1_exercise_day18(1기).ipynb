{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399157d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_row\", 1000)\n",
    "pd.set_option(\"display.max_column\", 100)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = \"https://raw.githubusercontent.com/Soyoung-Yoon/data_01/main/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6b196",
   "metadata": {},
   "source": [
    "**18-1) 수도권 지역 매출 분석**\n",
    "\n",
    "다음은 지역별 제품 매출 데이터를 담고 있는 데이터셋이다.\n",
    "데이터는 region, product, sales, date 컬럼으로 구성되어 있으며,\n",
    "sales는 각 제품의 일별 매출액을 나타낸다.\n",
    "\n",
    "다음에 따라 데이터를 처리하시오.\n",
    "- 1) 각 지역(region)별 평균 매출액(sales)을 계산한다.\n",
    "- 2) 각 지역별로 해당 지역의 평균 매출액보다 큰 매출액을 가진 데이터의 개수를 구한다.\n",
    "- 3) 위에서 구한 데이터의 개수가 가장 큰 지역의 제품 'A' 또는 'B'에 대한 sales 총합을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10120\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"sales_data02.csv\")\n",
    "# print(df.head(3))\n",
    "\n",
    "# 1. 각 지역(region)별 평균 매출액(sales)을 계산한다.\n",
    "s = df.groupby('region')['sales'].transform('mean')\n",
    "# print(s)\n",
    "\n",
    "# 2. 각 지역별로 해당 지역의 평균 매출액보다 큰 매출액을 가진 데이터의 개수를 구한다.\n",
    "df2 = df[df['sales'] > s].copy()\n",
    "max_region = df2['region'].value_counts().index[0]\n",
    "# print(max_region)\n",
    "\n",
    "#  3. 위에서 구한 데이터의 개수가 가장 큰 지역의 제품 'A' 또는 'B'에 대한 sales 총합을 구한다.\n",
    "cond = (df['region'] == max_region) & (df['product'].isin(['A','B']))\n",
    "result = df.loc[cond, 'sales'].sum()\n",
    "# print(result) # 34781 --> 10120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585dd2e",
   "metadata": {},
   "source": [
    "**18-2) 연도별 질병 사망률 분석**\n",
    "\n",
    "2014년부터 2024년까지의 주요 10대 질병에 대한 사망자수 및 발생건수를 기록한 데이터를 사용하여 사망률을 분석한다.\n",
    "\n",
    "다음 조건에 따라 분석을 수행하시오.\n",
    "- 1) 각 연도별로 각 질병에 대해 생존률을 계산한다.\n",
    "> 생존률 = 1 - (사망자수 / 발생건수)\n",
    "- 2) 연도별로 생존률이 가장 높은 질병명을 1개씩 선택한다.\n",
    "- 3) 선택된 연도별, 생존률이 가장 높은 질병들에 대해, 생존자수 총합을 정수형으로 출력한다.\n",
    "> 생존자수 = 발생건수 - 사망자수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27021\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"disease_data.csv\")\n",
    "# print(df.head(3))\n",
    "\n",
    "# 1. 각 연도별로 각 질병에 대해 생존률을 계산한다.\n",
    "# 생존률 = 1 - (사망자수 / 발생건수)\n",
    "df = df.set_index('연도')\n",
    "df1 = df[df['구분']=='사망자수'].drop(columns='구분') # 연도, 질병별 사망자수\n",
    "df2 = df[df['구분']=='발생건수'].drop(columns='구분')\n",
    "rate = 1 - (df1 / df2)\n",
    "# print(rate)\n",
    "\n",
    "# 2. 연도별로 생존률이 가장 높은 질병명을 1개씩 선택한다.\n",
    "s = rate.idxmax(axis=1)\n",
    "\n",
    "# 3. 선택된 연도별, 생존률이 가장 높은 질병들에 대해, 생존자수 총합을 정수형으로 출력한다.\n",
    "#    생존자수 = 발생건수 - 사망자수\n",
    "df3 = df2 - df1\n",
    "temp = [df3.loc[year, name] for year, name in zip(s.index, s.values)]\n",
    "result = int(sum(temp))\n",
    "print(result) # 27021\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe0724e",
   "metadata": {},
   "source": [
    "**18-3) 가구별 에너지 소비 격차 분석**\n",
    "\n",
    "가구의 연도별 에너지 사용량 데이터를 사용하여, 지역별 에너지 사용 패턴을 분석하여 에너지 소비 불균형 여부를 파악하고자 한다.\n",
    "\n",
    "다음 조건에 따라 분석을 수행하시오.\n",
    "- 1) Electricity와 Gas 사용량의 합을 '총에너지사용량'으로 계산하시오.\n",
    "- 2) 지역별로 연도(Year) 및 계절(Season)별 '총에너지사용량' 합계를 구하시오.\n",
    "- 3) 위의 결과를 사용해 각 지역(Region)별 에너지 사용량 평균과 중앙값의 절댓값 차이가 가장 큰 지역 이름을 문자열로 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81556e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Season Region  Electricity  Gas\n",
      "0  2018  Spring     서울          313  321\n",
      "1  2018  Spring     서울          877  363\n",
      "2  2018  Spring     서울          254  557\n",
      "서울\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"energy_data.csv\")\n",
    "print(df.head(3))\n",
    "\n",
    "# 1. Electricity와 Gas 사용량의 합을 '총에너지사용량'으로 계산하시오.\n",
    "df['Energy'] = df['Electricity'] + df['Gas']\n",
    "# print(df.head(3))\n",
    "\n",
    "# 2. 지역별로 연도(Year) 및 계절(Season)별 '총에너지사용량' 합계를 구하시오.\n",
    "df2 = df.groupby(['Region','Year','Season'])['Energy'].sum().reset_index()\n",
    "# print(df2.head(3))\n",
    "\n",
    "# 3. 위의 결과를 사용해 각 지역(Region)별 에너지 사용량 평균과 중앙값의 절댓값 차이가 가장 큰 지역 이름을 문자열로 출력하시오.\n",
    "df3 = df2.groupby('Region')['Energy'].agg(['mean', 'median'])\n",
    "result = (df3['mean'] - df3['median']).abs().idxmax()\n",
    "# print(result) # 서울\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf02231",
   "metadata": {},
   "source": [
    "**18-4) 차량 종류별 비율 분석**\n",
    "\n",
    "도로별, 차량유형별 통행량이 포함된 데이터를 사용하여 결측치를 해결하고, 통행량 분석을 한다.\n",
    "\n",
    "다음 조건에 따라 분석을 수행하시오.\n",
    "- 1) Count 컬럼의 결측치는 Date별, Vehicle_Type별 평균값으로 대체하시오.\n",
    "- 2) 1)의 결과에 대해, 일요일에 대한 데이터를 A, 일요일이 아닌 데이터를 B라고 한다.\n",
    "- 3) Road_Code별 통행량 평균을 A, B 각각에 대해  구한 뒤, B - A의 절대값을 구한다.\n",
    "- 4) 3)에서 구한 값 중 가장 큰 값에 대한 Road_Code를 찾아 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"traffic_data02.csv\")\n",
    "# print(df.head(3))\n",
    "\n",
    "# 1. Count 컬럼의 결측치는 Date별, Vehicle_Type별 평균값으로 대체하시오.\n",
    "# print(df.isna().sum().to_frame().T)\n",
    "s = df.groupby(['Date','Vehicle_Type'])['Count'].transform('mean')\n",
    "df['Count'] = df['Count'].fillna(s)\n",
    "# print(df.isna().sum().to_frame().T)\n",
    "\n",
    "# 2. 1)의 결과에 대해, 일요일에 대한 데이터를 A, 일요일이 아닌 데이터를 B라고 한다.\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Daynm'] = df['Date'].dt.day_name('ko_KR')\n",
    "# print(df.head(3))\n",
    "A = df[df['Daynm'] == '일요일'].copy()\n",
    "B = df[df['Daynm'] != '일요일'].copy()\n",
    "# print(A.shape, B.shape) # (40, 5) (208, 5)\n",
    "\n",
    "# 3. Road_Code별 통행량 평균을 A, B 각각에 대해 구한 뒤, B - A의 절대값을 구한다.\n",
    "A_mean = A.groupby('Road_Code')['Count'].mean().reset_index(name='A_mean')\n",
    "B_mean = B.groupby('Road_Code')['Count'].mean().reset_index(name='B_mean')\n",
    "diff = pd.merge(B_mean, A_mean, \"left\", \"Road_Code\")\n",
    "diff['mean_diff'] = abs(diff['B_mean'] - diff['A_mean'])\n",
    "\n",
    "# 4. 3)에서 구한 값 중 가장 큰 값에 대한 Road_Code를 찾아 출력하시오.\n",
    "max_diff = diff['mean_diff'].max()\n",
    "result = diff.loc[diff['mean_diff'] == max_diff, 'Road_Code'].values[0]\n",
    "print(result) # 204\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d8755",
   "metadata": {},
   "source": [
    "**18-5) 이상치 발생 빈도 분석**\n",
    "\n",
    "이벤트별 이상치의 개수를 분석하고자 한다.\n",
    "\n",
    "다음 조건에 따라 분석을 수행하시오.\n",
    "- 1) start_datetime을 기준으로, 1일부터 15일까지의 날짜에 해당하는 데이터만 대상으로 분석한다.\n",
    "- 2) 이벤트(event) 종류 별로 다음 기준에 따라 value 컬럼의 이상치 개수를 구해, 그 합을 출력하시오.\n",
    "> 이상치 = 값이 Q1 - 1.5 × IQR 미만이거나 Q3 + 1.5 × IQR 초과하는 데이터\n",
    "- 단, IQR = Q3 - Q1 (사분위 범위)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e49ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"event_log_01b_outlier.csv\")\n",
    "# print(df.head(3))\n",
    "\n",
    "# 1. start_datetime을 기준으로, 1일부터 15일까지의 날짜에 해당하는 데이터만 대상으로 분석한다.\n",
    "s = df['start_datetime'].astype('datetime64[ns]').dt.day\n",
    "df = df[(s >= 1) & (s <= 15)].copy()\n",
    "\n",
    "# 2. 이벤트(event) 종류 별로 다음 기준에 따라 value 컬럼의 이상치 개수를 구해, 그 합을 출력하시오.\n",
    "#    이상치 = 값이 Q1 - 1.5 × IQR 미만이거나 Q3 + 1.5 × IQR 초과하는 데이터\n",
    "#    단, IQR = Q3 - Q1 (사분위 범위)\n",
    "# Q1, Q3 = df['value'].quantile([0.25, 0.75])\n",
    "Q1 = df.groupby('event')['value'].transform(lambda x: x.quantile(0.25))\n",
    "Q3 = df.groupby('event')['value'].transform(lambda x: x.quantile(0.75))\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "temp = df[(df['value'] < lower) | (df['value'] > upper)]\n",
    "result = len(temp)\n",
    "print(result) # 56 --> 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4716c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
